{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7805617",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession \n",
    " \n",
    "spark_session = SparkSession.builder\\\n",
    "        .master(\"spark://192.168.2.129:7077\") \\\n",
    "        .appName(\"MSD_analysis_pt1_app\")\\\n",
    "        .config(\"spark.dynamicAllocation.enabled\", False)\\\n",
    "        .config(\"spark.dynamicAllocation.shuffleTracking.enabled\",True)\\\n",
    "        .config(\"spark.shuffle.service.enabled\", False)\\\n",
    "        .config(\"spark.dynamicAllocation.executorIdleTimeout\",\"30s\")\\\n",
    "        .config(\"spark.cores.max\", 4)\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4007a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = spark_session.read.csv('hdfs://192.168.2.129:50000/hdfs/data/MSD_Sub_as_CSV.csv', header=True)\n",
    "df2 = spark_session.read.csv('hdfs://192.168.2.129:50000/hdfs/data/MSD_Sub_as_CSV.csv', header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14b3ca2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "dfs = [df1,df2]\n",
    "\n",
    "#Switch range (loop count) to\n",
    "#24 for 500k songs\n",
    "#49 for 1million songs \n",
    "#99 for 2million songs\n",
    "#149 for 3million songs\n",
    "#199 for 4 million songs\n",
    "\n",
    "for i in range(24):\n",
    "    dfs.append(df1)\n",
    "    dfs.append(df2)\n",
    "    \n",
    "msd_df = reduce(DataFrame.unionAll, dfs)\n",
    "msd_df.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60091a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "msd_df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c3e821",
   "metadata": {},
   "outputs": [],
   "source": [
    "msd_df = msd_df.repartition(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c918fe10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "msd_df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a7a5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#msd_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77be4467",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#msd_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f170580",
   "metadata": {},
   "source": [
    "### T1: Famous (Familiarity above 0.5) artists with more than 6 fairly successful (hotness above 0.5) songs in the list that are most inconsistent in the hotness of their songs (std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81eb13ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import time\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import isnan\n",
    "from pyspark.sql.functions import col\n",
    "start_time = time.time()\n",
    "msd_df.select('ArtistName','ArtistFamiliarity', 'Title', 'Duration', 'Hotness', 'Year')\\\n",
    "                        .filter(~isnan('Hotness'))\\\n",
    "                        .filter(col('ArtistFamiliarity')>0.5)\\\n",
    "                        .filter(col('Hotness')>0.5)\\\n",
    "                        .groupBy('ArtistName')\\\n",
    "                        .agg(F.mean('Hotness'),\\\n",
    "                             F.max('Hotness'),\\\n",
    "                             F.mean('Duration'),\\\n",
    "                             F.mean('ArtistFamiliarity'),\\\n",
    "                             F.stddev('Hotness'),\\\n",
    "                             F.countDistinct('Title'))\\\n",
    "                        .filter(col('count(Title)')>6)\\\n",
    "                        .orderBy(col('stddev_samp(Hotness)').desc())\\\n",
    "                        .show()\n",
    "end_time = time.time()\n",
    "print(\"Exec-time:\", (end_time - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21aff4d0",
   "metadata": {},
   "source": [
    "##### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795bb0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "result_df = msd_df.select('ArtistName', 'ArtistFamiliarity', 'Title', 'Duration', 'Hotness', 'Year') \\\n",
    "    .filter(~isnan('Hotness')) \\\n",
    "    .filter(col('ArtistFamiliarity') > 0.5) \\\n",
    "    .filter(col('Hotness') > 0.5) \\\n",
    "    .groupBy('ArtistName') \\\n",
    "    .agg(F.mean('Hotness'), \\\n",
    "         F.max('Hotness'), \\\n",
    "         F.mean('Duration'), \\\n",
    "         F.mean('ArtistFamiliarity'), \\\n",
    "         F.stddev('Hotness'), \\\n",
    "         F.countDistinct('Title')) \\\n",
    "    .filter(col('count(Title)') > 6) \\\n",
    "    .orderBy(col('stddev_samp(Hotness)').desc()) \\\n",
    "    .limit(3) \\\n",
    "    .collect()\n",
    "\n",
    "artists = [row['ArtistName'] for row in result_df]\n",
    "hotness_means = [row['avg(Hotness)'] for row in result_df]\n",
    "hotness_stdevs = [row['stddev_samp(Hotness)'] for row in result_df]\n",
    "\n",
    "x_pos = [i for i, _ in enumerate(artists)]\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x_pos, hotness_means, color='tab:blue', alpha=0.5, yerr=hotness_stdevs)\n",
    "for i, v in enumerate(hotness_stdevs):\n",
    "    ax.text(i-0.1, hotness_means[i] + v + 0.02, \"{:.2f}\".format(v), fontsize=10)\n",
    "\n",
    "plt.xticks(x_pos, artists)\n",
    "plt.ylabel('avg(Hotness)')\n",
    "plt.xlabel('Artist')\n",
    "plt.title('Famous Aritists with highest inconsistency of Song Hotness')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a122b53",
   "metadata": {},
   "source": [
    "### T2: Development of Songduration and BPM over the decades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5196dc24",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import isnan\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "\n",
    "msd_df = msd_df.withColumn(\"Duration\", msd_df[\"Duration\"].cast(DoubleType()))\n",
    "msd_df = msd_df.withColumn(\"Tempo\", msd_df[\"Tempo\"].cast(DoubleType()))\n",
    "\n",
    "\n",
    "df_result = msd_df.select('Year', 'Tempo', 'Duration', 'ArtistFamiliarity')\\\n",
    "    .filter(msd_df.Year.between(1950,2009))\\\n",
    "    .groupBy(F.concat(F.floor((msd_df.Year - 1960) / 10) * 10 + 1960, F.lit('s')).alias('Decade'))\\\n",
    "    .agg(F.mean('Duration'),\\\n",
    "         F.min('Duration'),\\\n",
    "         F.mean('Tempo'),\\\n",
    "         F.max('Tempo'),\\\n",
    "         F.mean('ArtistFamiliarity'),\\\n",
    "         F.count('Year'))\\\n",
    "    .orderBy(col(\"Decade\").desc())\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871f0b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import isnan\n",
    "from pyspark.sql.functions import col\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "msd_df = msd_df.withColumn(\"Duration\", msd_df[\"Duration\"].cast(DoubleType()))\n",
    "msd_df = msd_df.withColumn(\"Tempo\", msd_df[\"Tempo\"].cast(DoubleType()))\n",
    "\n",
    "\n",
    "df_result = msd_df.select('Year', 'Tempo', 'Duration', 'ArtistFamiliarity')\\\n",
    "    .filter(msd_df.Year.between(1950,2009))\\\n",
    "    .groupBy(F.concat(F.floor((msd_df.Year - 1960) / 10) * 10 + 1960, F.lit('s')).alias('Decade'))\\\n",
    "    .agg(F.mean('Duration'),\\\n",
    "         F.min('Duration'),\\\n",
    "         F.mean('Tempo'),\\\n",
    "         F.max('Tempo'),\\\n",
    "         F.mean('ArtistFamiliarity'),\\\n",
    "         F.count('Year'))\\\n",
    "    .orderBy(col(\"Decade\").desc())\\\n",
    "    .collect()\n",
    "\n",
    "\n",
    "\n",
    "df_pandas = pd.DataFrame(df_result, columns=['Decade', 'avg(Duration)', 'min(Duration)', 'avg(Tempo)', 'max(Tempo)', 'avg(ArtistFamiliarity)', 'count(Year)']).iloc[::-1]\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "df_pandas.plot(x='Decade', y='avg(Duration)', ax=ax1, label='Duration', color='tab:blue')\n",
    "df_pandas.plot(x='Decade', y='avg(Tempo)', ax=ax2, label='Tempo', color='tab:red')\n",
    "\n",
    "ax1.set_xlabel('Decade')\n",
    "ax1.set_ylabel('Duration')\n",
    "ax2.set_ylabel('Tempo')\n",
    "ax2.legend(loc = 'center right')\n",
    "plt.title('Trendlines of Duration and Tempo over the Decades')\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161bad13",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_session.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c72b5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
